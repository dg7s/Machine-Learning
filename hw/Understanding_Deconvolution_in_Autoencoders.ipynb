{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "xl_-W_aXqjJ2",
      "metadata": {
        "id": "xl_-W_aXqjJ2"
      },
      "source": [
        "# Lab 11 - Autoencoders\n",
        "\n",
        "Dominik Gaweł\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dg7s/Machine-Learning/blob/main/hw/Understanding_Deconvolution_in_Autoencoders.ipynb)\n",
        "-------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Ar3Nf6gOX4Y",
      "metadata": {
        "id": "4Ar3Nf6gOX4Y"
      },
      "source": [
        "# **Homework Assignment: Understanding Deconvolution in Autoencoders**\n",
        "---------------\n",
        "\n",
        "In class, we worked with autoencoders built from multilayer perceptrons (MLPs). However, encoders are often constructed using convolutional architectures to better capture spatial patterns. In this assignment, you'll explore how the decoder can use deconvolutional (transposed convolution) layers to reverse and mirror the operations performed by the convolutional encoder.\n",
        "\n",
        "While convolutional encoders are relatively well understood, **decoding (or upsampling) the compressed representation** using **deconvolutional layers** (also known as **transposed convolutions**) often raises questions.\n",
        "\n",
        "This assignment is particularly relevant because deconvolution is a core component of the U-Net architecture, a prominent neural network used extensively in image segmentation tasks.\n",
        "\n",
        "Your main objective is to deeply understand **how transposed convolution layers work**, and explain them in both words and visuals.\n",
        "\n",
        "\n",
        "## **The Objective**\n",
        "\n",
        "Understand and clearly explain how **transposed convolutions** work. Use 2D transposed convolutions and a small grid of 2D points as a working example.\n",
        "\n",
        "You may need to do some additional reading to complete this assignment.\n",
        "\n",
        "## **Tasks & Deliverables**\n",
        "\n",
        "### 1. **Theory Exploration**\n",
        "\n",
        "Using markdown cells in your Colab notebook, answer the following:\n",
        "\n",
        "- What is a **transposed convolution**?\n",
        "- How does it differ from a regular convolution?\n",
        "- How does it upsample feature maps?\n",
        "- What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?\n",
        "- To earn full two points, your explanation must be detailed enough for a reader to reproduce the upsampling process step by step.\n",
        "\n",
        "\n",
        "### 2. **Manual Diagram (by your hand, not a generated image)**\n",
        "\n",
        "Carefully plan and draw **by hand** a diagram or a set of diagrams that:\n",
        "\n",
        "- Explain the process of using **transposed convolution**.\n",
        "- Use an example of a **small input grid of 2D points** which gets expanded into a larger output grid.\n",
        "- Explain how stride, padding, and the kernel shape affect the result.\n",
        "- Show intermediate steps of the operation, not just input and output.\n",
        "\n",
        "**Scan or photograph your diagram(s)**, and upload it to your **GitHub repository** for this course.\n",
        "\n",
        "Then embed it in your Colab notebook using markdown (you can find examples on *how to do it* in previous notebooks related to this class, e.g. the one on linear regression or the one on the MLP network).\n",
        "\n",
        "\n",
        "### 3. **Publish on GitHub**  \n",
        "   - Place the Colab notebook in your **GitHub repository** for this course.\n",
        "   - In your repository’s **README**, add a **link** to the notebook and also include an **“Open in Colab”** badge at the top of the notebook so it can be launched directly from GitHub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Jhgo2Pkqz0hl",
      "metadata": {
        "id": "Jhgo2Pkqz0hl"
      },
      "source": [
        "## 1. Theory Exploration\n",
        "\n",
        "- ### What is a **transposed convolution**?\n",
        "  A transposed convolution reverses the spatial downsampling of a standard convolution—though it is not its exact inverse. Instead of sliding a kernel over an input to produce a smaller output, it:\n",
        "\n",
        "  1. **Starts** with a zero‑filled output grid of the target size\n",
        "  $(X_{in}-1)\\times\\text{stride}+\\text{dilation}\\times(\\text{kernel_size}-1)+1$. `dilation`, if specified dilates the kernel, not the input.  \n",
        "  2. **Scatters** each non‑zero input value: multiply the entire K×K kernel by that scalar and adds it into the output grid at the position determined by stride and dilation.\n",
        "  3. **Accumulates** overlapping results, then adjusts the final output using `padding` and `output_padding` options.\n",
        "---\n",
        "\n",
        "- ### How does it differ from a regular convolution?\n",
        "\n",
        "| Aspect                    | Regular Convolution      | Transposed Convolution             |\n",
        "|---------------------------|--------------------------|------------------------------------|\n",
        "| **Spatial size change**   | Usually **decreases**    | Usually **Increases**                      |\n",
        "| **Kernel operation**            | Multiplies each kernel element with the corresponding value in an input patch and sums    | Multiplies the entire kernel by each single non‑zero input scalar and adds that block to the output         |\n",
        "| **Padding effect**         | Increases output spatial size | Decreases output spatial size |\n",
        "| **Typical use**           | Feature extraction       | Learned upsampling / decoding      |\n",
        "\n",
        "---\n",
        "- ### How does it upsample feature maps?\n",
        "\n",
        "  1. **Initialize Output**  \n",
        "    - Create a zero matrix: $((H_{in}-1)\\times\\text{stride}[0]+\\text{dilation}[0]\\times(\\text{kernel_size}[0]-1)+1) \\times ((W_{in}-1)\\times\\text{stride}[1]+\\text{dilation}[1]\\times(\\text{kernel_size}[1]-1)+1)$  \n",
        "\n",
        "  2. **Scatter Inputs**  \n",
        "    - For each input element v at $(i,j)$, compute its top‑left output index $(i×S,j×S)$, multiply the $K×K$ kernel by v, and add that scaled kernel block into the zero‑initialized output grid at that position.\n",
        "\n",
        "  3. **Overlap & Accumulation**\n",
        "    - Where kernel applications overlap, their outputs are summed, resulting in the upsampled feature map.\n",
        "\n",
        "  4. **Trimming with Padding**  \n",
        "    - After convolution, remove P rows from the top and bottom and P columns from the left and right of the result.\n",
        "\n",
        "---\n",
        "\n",
        "- ### What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?\n",
        "\n",
        "  - **Kernel size (K)**  \n",
        "    - Size of the square filter.  \n",
        "    - Larger kernels increase overlap between expanded activations, producing smoother interpolation.\n",
        "\n",
        "  - **Stride (S)**  \n",
        "    - Determines both how far the kernel moves and how many zeros are inserted.  \n",
        "    - A larger S inserts more zeros, yielding a larger output with more widely spaced contributions.\n",
        "\n",
        "  - **Padding (P)**  \n",
        "    - Specifies how many rows and columns to trim from the convolved result’s borders.  \n",
        "    - Higher P trims more, reducing output dimensions and smoothing edge transitions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E4lLaXNCz0s7",
      "metadata": {
        "id": "E4lLaXNCz0s7"
      },
      "source": [
        "## 2. Manual Diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XKaocqsZ0qc3",
      "metadata": {
        "id": "XKaocqsZ0qc3"
      },
      "source": [
        "https://docs.pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "13sHrkUXz_F7",
      "metadata": {
        "id": "13sHrkUXz_F7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "IP3aa-WCMiIq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP3aa-WCMiIq",
        "outputId": "0732675d-0cd8-41a8-9654-7af38ab48c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[3., 2., 1.],\n",
            "          [0., 5., 2.],\n",
            "          [1., 4., 7.]]]])\n"
          ]
        }
      ],
      "source": [
        "inp  = torch.Tensor([[[[3, 2, 1],\n",
        "                      [0, 5, 2],\n",
        "                      [1, 4, 7]]]])\n",
        "\n",
        "kernel = torch.Tensor([[[[1, 2],\n",
        "                        [3, 4]]]])\n",
        "print(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "WO5-9BojM3UY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO5-9BojM3UY",
        "outputId": "0d591563-5d49-46c6-cd6d-1416a7c0190d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[12.,  6.,  8.,  3.],\n",
            "          [ 0.,  5., 10.,  2.],\n",
            "          [ 0., 15., 20.,  6.],\n",
            "          [ 2.,  4.,  8.,  7.]]]])\n"
          ]
        }
      ],
      "source": [
        "padding = 1\n",
        "stride = 2\n",
        "out = F.conv_transpose2d(inp, kernel, stride=stride, padding=padding)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-3cBy0OSjdvX",
      "metadata": {
        "id": "-3cBy0OSjdvX"
      },
      "source": [
        "![img](https://raw.githubusercontent.com/dg7s/Machine-Learning/refs/heads/main/hw/conv_transpose2d.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
